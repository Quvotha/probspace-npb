{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28cfd3a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:39.862624Z",
     "iopub.status.busy": "2021-06-09T13:05:39.862624Z",
     "iopub.status.idle": "2021-06-09T13:05:39.879059Z",
     "shell.execute_reply": "2021-06-09T13:05:39.879059Z"
    }
   },
   "outputs": [],
   "source": [
    "NOTE = 'Decision-function/Predict-probaの取得'\n",
    "notebook_name = '087'\n",
    "CV = 'GroupK-Fold(pitcherID)'\n",
    "group_col = 'pitcherID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172cf880",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:39.879059Z",
     "iopub.status.busy": "2021-06-09T13:05:39.879059Z",
     "iopub.status.idle": "2021-06-09T13:05:42.023288Z",
     "shell.execute_reply": "2021-06-09T13:05:42.023288Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import ComplementNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "SCRIPT_PATH = os.path.join('..', 'scripts')\n",
    "if SCRIPT_PATH not in sys.path:\n",
    "    sys.path.append(SCRIPT_PATH)\n",
    "from features import CATEGORICAL_FEATURES, VECTOR_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9cb5729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:42.023288Z",
     "iopub.status.busy": "2021-06-09T13:05:42.023288Z",
     "iopub.status.idle": "2021-06-09T13:05:42.054560Z",
     "shell.execute_reply": "2021-06-09T13:05:42.054560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "087_submission.csv 087\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = os.path.basename(notebook_name)\n",
    "SUB_FILENAME = notebook_name[:3] + '_submission.csv'\n",
    "assert(SUB_FILENAME not in pd.read_csv('submissions.csv').filename.tolist())\n",
    "print(SUB_FILENAME, OUTPUT_DIR)\n",
    "if not os.path.isdir(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "# class_weights for CatBoostClassifier, copied from 020\n",
    "CLASS_WEIGHTS = {\n",
    "        0: 0.33822833,\n",
    "        1: 0.4574968, \n",
    "        2: 0.71590909,\n",
    "        3: 1.00280899,\n",
    "        4: 3.17333333,\n",
    "        5: 11.45454545,\n",
    "        6: 194.72727273,\n",
    "        7: 17.85\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a9dd82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:42.070148Z",
     "iopub.status.busy": "2021-06-09T13:05:42.054560Z",
     "iopub.status.idle": "2021-06-09T13:05:44.399734Z",
     "shell.execute_reply": "2021-06-09T13:05:44.399734Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join('001_EDA', 'train_data_preprocessed.csv'))\n",
    "test = pd.read_csv(os.path.join('001_EDA', 'test_data_preprocessed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abebfeec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:44.399734Z",
     "iopub.status.busy": "2021-06-09T13:05:44.399734Z",
     "iopub.status.idle": "2021-06-09T13:05:44.415358Z",
     "shell.execute_reply": "2021-06-09T13:05:44.415358Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = train[group_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1522d341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:44.415358Z",
     "iopub.status.busy": "2021-06-09T13:05:44.415358Z",
     "iopub.status.idle": "2021-06-09T13:05:44.430986Z",
     "shell.execute_reply": "2021-06-09T13:05:44.430986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 384, 107)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimal features\n",
    "minimal_features = [\n",
    "    'inningNo',\n",
    "    'totalPitchingCount',\n",
    "    'B',\n",
    "    'S',\n",
    "    'O',\n",
    "    'b1',\n",
    "    'b2',\n",
    "    'b3',\n",
    "    'numRunners',\n",
    "    'batterID',\n",
    "    'pitcherID',\n",
    "    'Match',\n",
    "    'isBatterHandLeft',\n",
    "    'isPitcherHandLeft',\n",
    "    'isBatterPitcher',\n",
    "    'isBottom',\n",
    "    'batterTeam',\n",
    "    'pitcherTeam',\n",
    "]\n",
    "\n",
    "# categorical_features = [f for f in minimal_features if f in CATEGORICAL_FEATURES]\n",
    "# discrete_features = list(set(minimal_features) - set(categorical_features))\n",
    "# print(categorical_features)\n",
    "# print(discrete_features)\n",
    "\n",
    "# Execute if categories should be one-hot style\n",
    "## categorical features\n",
    "# for c in CATEGORICAL_FEATURES:\n",
    "#     assert(train[c].isin(test[c]).sum() == train.shape[0])\n",
    "#     assert(test[c].isin(train[c]).sum() == test.shape[0])\n",
    "# train = pd.get_dummies(train, columns=CATEGORICAL_FEATURES, drop_first=True)\n",
    "# test = pd.get_dummies(test, columns=CATEGORICAL_FEATURES, drop_first=True)\n",
    "# assert(set(train.columns.tolist()) - set(test.columns.tolist()) == {'y'})\n",
    "# assert(set(test.columns.tolist()) - set(train.columns.tolist()) == set())\n",
    "# categorical_features = []\n",
    "# for c in CATEGORICAL_FEATURES:\n",
    "#     categorical_features += [c_ for c_ in train.columns if c_.startswith(f'{c}_')]\n",
    "categorical_features = CATEGORICAL_FEATURES\n",
    "## vector features\n",
    "vector_features = VECTOR_FEATURES\n",
    "## discrete features\n",
    "discrete_features = [c for c in train.columns\n",
    "                     if c not in ['y', 'id'] + vector_features + categorical_features]\n",
    "## all features\n",
    "features = categorical_features + discrete_features + vector_features\n",
    "\n",
    "len(categorical_features), len(vector_features), len(discrete_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ddbf71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:44.430986Z",
     "iopub.status.busy": "2021-06-09T13:05:44.430986Z",
     "iopub.status.idle": "2021-06-09T13:05:44.446978Z",
     "shell.execute_reply": "2021-06-09T13:05:44.446978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batterID',\n",
       " 'pitcherID',\n",
       " 'Match',\n",
       " 'isBatterHandLeft',\n",
       " 'isPitcherHandLeft',\n",
       " 'isBatterPitcher',\n",
       " 'isBottom',\n",
       " 'batterTeam',\n",
       " 'pitcherTeam',\n",
       " 'b1',\n",
       " 'b2',\n",
       " 'b3']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5df28223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:44.446978Z",
     "iopub.status.busy": "2021-06-09T13:05:44.446978Z",
     "iopub.status.idle": "2021-06-09T13:05:44.462601Z",
     "shell.execute_reply": "2021-06-09T13:05:44.462601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['totalPitchingCount',\n",
       " 'B',\n",
       " 'S',\n",
       " 'O',\n",
       " 'inningNo',\n",
       " 'numRunners',\n",
       " 'pitcherHoursElapsed',\n",
       " 'pitcherNumGamesParticipated',\n",
       " 'batterHoursElapsed',\n",
       " 'batterNumGamesParticipated',\n",
       " 'speedcount',\n",
       " 'speedmean',\n",
       " 'speedstd',\n",
       " 'speedmin',\n",
       " 'speed25%',\n",
       " 'speed50%',\n",
       " 'speed75%',\n",
       " 'speedmax',\n",
       " 'speedrange',\n",
       " 'speedmeanDiff',\n",
       " 'speedstdDiff',\n",
       " 'speedminDiff',\n",
       " 'speed25%Diff',\n",
       " 'speed50%Diff',\n",
       " 'speed75%Diff',\n",
       " 'speedmaxDiff',\n",
       " 'pitchTypeRatioカットファストボール',\n",
       " 'pitchTypeRatioカーブ',\n",
       " 'pitchTypeRatioシュート',\n",
       " 'pitchTypeRatioシンカー',\n",
       " 'pitchTypeRatioストレート',\n",
       " 'pitchTypeRatioスライダー',\n",
       " 'pitchTypeRatioチェンジアップ',\n",
       " 'pitchTypeRatioフォーク',\n",
       " 'battersFaced',\n",
       " 'gameIDCount',\n",
       " 'numInningsSum',\n",
       " 'inningFromMin',\n",
       " 'inningFromMean',\n",
       " 'inningFromMedian',\n",
       " 'inningFromMax',\n",
       " 'inningFromStd',\n",
       " 'inningToMin',\n",
       " 'inningToMean',\n",
       " 'inningToMedian',\n",
       " 'inningToMax',\n",
       " 'inningToStd',\n",
       " 'pitcherNumStrikeOuts',\n",
       " 'pitcherNumWalks',\n",
       " 'hitsAllowed',\n",
       " 'K/9',\n",
       " 'BB/9',\n",
       " 'K1p/BB1p',\n",
       " 'whips',\n",
       " 'pitchersFaced',\n",
       " 'batterNumStrikeOuts',\n",
       " 'batterNumWalks',\n",
       " 'hits',\n",
       " 'battingTypeB',\n",
       " 'battingTypeF',\n",
       " 'battingTypeG',\n",
       " 'battingTypeL',\n",
       " 'battingTypeN',\n",
       " 'battingTypeP',\n",
       " 'distcount',\n",
       " 'distmean',\n",
       " 'diststd',\n",
       " 'distmin',\n",
       " 'dist25%',\n",
       " 'dist50%',\n",
       " 'dist75%',\n",
       " 'distmax',\n",
       " 'distrange',\n",
       " 'distcountDiff',\n",
       " 'distmeanDiff',\n",
       " 'diststdDiff',\n",
       " 'distminDiff',\n",
       " 'dist25%Diff',\n",
       " 'dist50%Diff',\n",
       " 'dist75%Diff',\n",
       " 'distmaxDiff',\n",
       " 'distDirA',\n",
       " 'distDirB',\n",
       " 'distDirC',\n",
       " 'distDirD',\n",
       " 'distDirE',\n",
       " 'distDirF',\n",
       " 'distDirG',\n",
       " 'distDirH',\n",
       " 'distDirI',\n",
       " 'distDirJ',\n",
       " 'distDirK',\n",
       " 'distDirL',\n",
       " 'distDirM',\n",
       " 'distDirN',\n",
       " 'distDirO',\n",
       " 'distDirP',\n",
       " 'distDirQ',\n",
       " 'distDirR',\n",
       " 'distDirS',\n",
       " 'distDirT',\n",
       " 'distDirU',\n",
       " 'distDirV',\n",
       " 'distDirW',\n",
       " 'distDirX',\n",
       " 'distDirY',\n",
       " 'distDirZ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36d1d802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:44.462601Z",
     "iopub.status.busy": "2021-06-09T13:05:44.462601Z",
     "iopub.status.idle": "2021-06-09T13:05:44.478193Z",
     "shell.execute_reply": "2021-06-09T13:05:44.478193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ballPositionLabel__no_data__',\n",
       " 'ど真ん中',\n",
       " '内角中心',\n",
       " '内角低め',\n",
       " '内角高め',\n",
       " '外角中心',\n",
       " '外角低め',\n",
       " '外角高め',\n",
       " '真ん中低め',\n",
       " '真ん中高め',\n",
       " 'ballPositionLabeld1',\n",
       " 'ballPositionLabeld2',\n",
       " 'ballPositionLabeld3',\n",
       " 'ballPositionLabeld4',\n",
       " 'ballPositionLabeld5',\n",
       " 'ballPositionLabeld6',\n",
       " 'ballPositionLabeld7',\n",
       " 'ballPositionLabeld8',\n",
       " 'ballPositionLabeld9',\n",
       " 'ballPositionLabeld10',\n",
       " 'ballPositionLabeld11',\n",
       " 'ballPositionLabeld12',\n",
       " 'ballPositionLabeld13',\n",
       " 'ballPositionLabeld14',\n",
       " 'ballPositionLabeld15',\n",
       " 'ballPositionLabeld16',\n",
       " 'ballPositionLabeld17',\n",
       " 'ballPositionLabeld18',\n",
       " 'ballPositionLabeld19',\n",
       " 'ballPositionLabeld20',\n",
       " 'ballPositionLabeld21',\n",
       " 'ballPositionLabeld22',\n",
       " 'ballPositionLabeld23',\n",
       " 'ballPositionLabeld24',\n",
       " 'ballPositionLabeld25',\n",
       " 'ballPositionLabeld26',\n",
       " 'ballPositionLabeld27',\n",
       " 'ballPositionLabeld28',\n",
       " 'ballPositionLabeld29',\n",
       " 'ballPositionLabeld30',\n",
       " 'ballPositionLabeld31',\n",
       " 'ballPositionLabeld32',\n",
       " 'ballPositionLabeld33',\n",
       " 'ballPositionLabeld34',\n",
       " 'ballPositionLabeld35',\n",
       " 'ballPositionLabeld36',\n",
       " 'ballPositionLabeld37',\n",
       " 'ballPositionLabeld38',\n",
       " 'ballPositionLabeld39',\n",
       " 'ballPositionLabeld40',\n",
       " 'ballPositionLabeld41',\n",
       " 'ballPositionLabeld42',\n",
       " 'ballPositionLabeld43',\n",
       " 'ballPositionLabeld44',\n",
       " 'ballPositionLabeld45',\n",
       " 'ballPositionLabeld46',\n",
       " 'ballPositionLabeld47',\n",
       " 'ballPositionLabeld48',\n",
       " 'ballPositionLabeld49',\n",
       " 'ballPositionLabeld50',\n",
       " 'pitchType__no_data__',\n",
       " 'カットファストボール',\n",
       " 'カーブ',\n",
       " 'シュート',\n",
       " 'シンカー',\n",
       " 'ストレート',\n",
       " 'スライダー',\n",
       " 'チェンジアップ',\n",
       " 'フォーク',\n",
       " 'pitchTyped1',\n",
       " 'pitchTyped2',\n",
       " 'pitchTyped3',\n",
       " 'pitchTyped4',\n",
       " 'pitchTyped5',\n",
       " 'pitchTyped6',\n",
       " 'pitchTyped7',\n",
       " 'pitchTyped8',\n",
       " 'pitchTyped9',\n",
       " 'pitchTyped10',\n",
       " 'pitchTyped11',\n",
       " 'pitchTyped12',\n",
       " 'pitchTyped13',\n",
       " 'pitchTyped14',\n",
       " 'pitchTyped15',\n",
       " 'pitchTyped16',\n",
       " 'pitchTyped17',\n",
       " 'pitchTyped18',\n",
       " 'pitchTyped19',\n",
       " 'pitchTyped20',\n",
       " 'pitchTyped21',\n",
       " 'pitchTyped22',\n",
       " 'pitchTyped23',\n",
       " 'pitchTyped24',\n",
       " 'pitchTyped25',\n",
       " 'pitchTyped26',\n",
       " 'pitchTyped27',\n",
       " 'pitchTyped28',\n",
       " 'pitchTyped29',\n",
       " 'pitchTyped30',\n",
       " 'pitchTyped31',\n",
       " 'pitchTyped32',\n",
       " 'pitchTyped33',\n",
       " 'pitchTyped34',\n",
       " 'pitchTyped35',\n",
       " 'pitchTyped36',\n",
       " 'pitchTyped37',\n",
       " 'pitchTyped38',\n",
       " 'pitchTyped39',\n",
       " 'pitchTyped40',\n",
       " 'pitchTyped41',\n",
       " 'pitchTyped42',\n",
       " 'pitchTyped43',\n",
       " 'pitchTyped44',\n",
       " 'pitchTyped45',\n",
       " 'pitchTyped46',\n",
       " 'pitchTyped47',\n",
       " 'pitchTyped48',\n",
       " 'pitchTyped49',\n",
       " 'pitchTyped50',\n",
       " '10a',\n",
       " '10b',\n",
       " '10c',\n",
       " '10d',\n",
       " '10e',\n",
       " '10f',\n",
       " '10g',\n",
       " '10h',\n",
       " '10i',\n",
       " '10j',\n",
       " '10k',\n",
       " '11a',\n",
       " '11b',\n",
       " '11c',\n",
       " '11d',\n",
       " '11e',\n",
       " '11f',\n",
       " '11g',\n",
       " '11h',\n",
       " '11i',\n",
       " '11j',\n",
       " '11k',\n",
       " '12a',\n",
       " '12b',\n",
       " '12c',\n",
       " '12d',\n",
       " '12e',\n",
       " '12f',\n",
       " '12g',\n",
       " '12h',\n",
       " '12i',\n",
       " '12j',\n",
       " '12k',\n",
       " '13a',\n",
       " '13b',\n",
       " '13c',\n",
       " '13d',\n",
       " '13e',\n",
       " '13f',\n",
       " '13g',\n",
       " '13h',\n",
       " '13i',\n",
       " '13j',\n",
       " '13k',\n",
       " '14a',\n",
       " '14b',\n",
       " '14c',\n",
       " '14d',\n",
       " '14e',\n",
       " '14f',\n",
       " '14g',\n",
       " '14h',\n",
       " '14i',\n",
       " '14j',\n",
       " '14k',\n",
       " '15a',\n",
       " '15b',\n",
       " '15c',\n",
       " '15d',\n",
       " '15e',\n",
       " '15f',\n",
       " '15g',\n",
       " '15h',\n",
       " '15i',\n",
       " '15j',\n",
       " '15k',\n",
       " '16a',\n",
       " '16b',\n",
       " '16c',\n",
       " '16d',\n",
       " '16e',\n",
       " '16f',\n",
       " '16g',\n",
       " '16h',\n",
       " '16i',\n",
       " '16j',\n",
       " '16k',\n",
       " '17a',\n",
       " '17b',\n",
       " '17c',\n",
       " '17d',\n",
       " '17e',\n",
       " '17f',\n",
       " '17g',\n",
       " '17h',\n",
       " '17i',\n",
       " '17j',\n",
       " '17k',\n",
       " '18d',\n",
       " '18e',\n",
       " '18f',\n",
       " '18g',\n",
       " '18h',\n",
       " '18i',\n",
       " '18j',\n",
       " '18k',\n",
       " '19d',\n",
       " '19e',\n",
       " '19f',\n",
       " '19g',\n",
       " '19h',\n",
       " '19i',\n",
       " '19j',\n",
       " '19k',\n",
       " '1a',\n",
       " '1b',\n",
       " '1c',\n",
       " '1d',\n",
       " '1e',\n",
       " '1f',\n",
       " '1g',\n",
       " '1h',\n",
       " '1i',\n",
       " '1j',\n",
       " '1k',\n",
       " '20a',\n",
       " '20b',\n",
       " '20d',\n",
       " '20e',\n",
       " '20f',\n",
       " '20g',\n",
       " '20h',\n",
       " '20i',\n",
       " '20j',\n",
       " '20k',\n",
       " '21a',\n",
       " '21b',\n",
       " '21c',\n",
       " '21d',\n",
       " '21e',\n",
       " '21f',\n",
       " '21g',\n",
       " '21h',\n",
       " '21i',\n",
       " '21j',\n",
       " '21k',\n",
       " '2b',\n",
       " '2d',\n",
       " '2e',\n",
       " '2f',\n",
       " '2g',\n",
       " '2h',\n",
       " '2i',\n",
       " '2j',\n",
       " '2k',\n",
       " '3b',\n",
       " '3c',\n",
       " '3d',\n",
       " '3e',\n",
       " '3f',\n",
       " '3g',\n",
       " '3h',\n",
       " '3i',\n",
       " '3j',\n",
       " '3k',\n",
       " '4b',\n",
       " '4d',\n",
       " '4e',\n",
       " '4f',\n",
       " '4g',\n",
       " '4h',\n",
       " '4i',\n",
       " '4j',\n",
       " '4k',\n",
       " '5d',\n",
       " '5e',\n",
       " '5f',\n",
       " '5g',\n",
       " '5h',\n",
       " '5i',\n",
       " '5j',\n",
       " '5k',\n",
       " '6b',\n",
       " '6d',\n",
       " '6e',\n",
       " '6f',\n",
       " '6g',\n",
       " '6h',\n",
       " '6i',\n",
       " '6j',\n",
       " '6k',\n",
       " '7a',\n",
       " '7b',\n",
       " '7c',\n",
       " '7d',\n",
       " '7e',\n",
       " '7f',\n",
       " '7g',\n",
       " '7h',\n",
       " '7i',\n",
       " '7j',\n",
       " '7k',\n",
       " '8a',\n",
       " '8b',\n",
       " '8c',\n",
       " '8d',\n",
       " '8e',\n",
       " '8f',\n",
       " '8g',\n",
       " '8h',\n",
       " '8i',\n",
       " '8j',\n",
       " '8k',\n",
       " '9a',\n",
       " '9b',\n",
       " '9c',\n",
       " '9d',\n",
       " '9e',\n",
       " '9f',\n",
       " '9g',\n",
       " '9h',\n",
       " '9i',\n",
       " '9j',\n",
       " '9k',\n",
       " 'ballXY__no_data__',\n",
       " 'ballXYd1',\n",
       " 'ballXYd2',\n",
       " 'ballXYd3',\n",
       " 'ballXYd4',\n",
       " 'ballXYd5',\n",
       " 'ballXYd6',\n",
       " 'ballXYd7',\n",
       " 'ballXYd8',\n",
       " 'ballXYd9',\n",
       " 'ballXYd10',\n",
       " 'ballXYd11',\n",
       " 'ballXYd12',\n",
       " 'ballXYd13',\n",
       " 'ballXYd14',\n",
       " 'ballXYd15',\n",
       " 'ballXYd16',\n",
       " 'ballXYd17',\n",
       " 'ballXYd18',\n",
       " 'ballXYd19',\n",
       " 'ballXYd20',\n",
       " 'ballXYd21',\n",
       " 'ballXYd22',\n",
       " 'ballXYd23',\n",
       " 'ballXYd24',\n",
       " 'ballXYd25',\n",
       " 'ballXYd26',\n",
       " 'ballXYd27',\n",
       " 'ballXYd28',\n",
       " 'ballXYd29',\n",
       " 'ballXYd30',\n",
       " 'ballXYd31',\n",
       " 'ballXYd32',\n",
       " 'ballXYd33',\n",
       " 'ballXYd34',\n",
       " 'ballXYd35',\n",
       " 'ballXYd36',\n",
       " 'ballXYd37',\n",
       " 'ballXYd38',\n",
       " 'ballXYd39',\n",
       " 'ballXYd40',\n",
       " 'ballXYd41',\n",
       " 'ballXYd42',\n",
       " 'ballXYd43',\n",
       " 'ballXYd44',\n",
       " 'ballXYd45',\n",
       " 'ballXYd46',\n",
       " 'ballXYd47',\n",
       " 'ballXYd48',\n",
       " 'ballXYd49',\n",
       " 'ballXYd50']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec6e9c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:44.478193Z",
     "iopub.status.busy": "2021-06-09T13:05:44.478193Z",
     "iopub.status.idle": "2021-06-09T13:05:44.493821Z",
     "shell.execute_reply": "2021-06-09T13:05:44.493821Z"
    }
   },
   "outputs": [],
   "source": [
    "# features = [c for c in train.columns if c not in ('id', 'y')]\n",
    "# assert(set(features) - set(test.columns.tolist()) == set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "131c14e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:44.493821Z",
     "iopub.status.busy": "2021-06-09T13:05:44.493821Z",
     "iopub.status.idle": "2021-06-09T13:05:44.509466Z",
     "shell.execute_reply": "2021-06-09T13:05:44.509466Z"
    }
   },
   "outputs": [],
   "source": [
    "# discrete_features = [f for f in features if f not in categorical_features]\n",
    "# discrete_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d1e456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:44.509466Z",
     "iopub.status.busy": "2021-06-09T13:05:44.509466Z",
     "iopub.status.idle": "2021-06-09T13:05:44.525029Z",
     "shell.execute_reply": "2021-06-09T13:05:44.525029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [120,\n",
       "  478,\n",
       "  504,\n",
       "  607,\n",
       "  587,\n",
       "  107,\n",
       "  136,\n",
       "  447,\n",
       "  363,\n",
       "  2,\n",
       "  618,\n",
       "  593,\n",
       "  616,\n",
       "  597,\n",
       "  407,\n",
       "  48,\n",
       "  58,\n",
       "  4,\n",
       "  394,\n",
       "  49],\n",
       " '1': [311,\n",
       "  305,\n",
       "  269,\n",
       "  143,\n",
       "  224,\n",
       "  182,\n",
       "  267,\n",
       "  55,\n",
       "  156,\n",
       "  550,\n",
       "  371,\n",
       "  336,\n",
       "  575,\n",
       "  158,\n",
       "  400,\n",
       "  211,\n",
       "  647,\n",
       "  222,\n",
       "  493,\n",
       "  528],\n",
       " '2': [130,\n",
       "  651,\n",
       "  298,\n",
       "  448,\n",
       "  387,\n",
       "  405,\n",
       "  634,\n",
       "  438,\n",
       "  102,\n",
       "  245,\n",
       "  507,\n",
       "  190,\n",
       "  147,\n",
       "  520,\n",
       "  169,\n",
       "  210,\n",
       "  409,\n",
       "  595,\n",
       "  494,\n",
       "  630],\n",
       " '3': [247,\n",
       "  128,\n",
       "  282,\n",
       "  185,\n",
       "  657,\n",
       "  288,\n",
       "  459,\n",
       "  45,\n",
       "  419,\n",
       "  16,\n",
       "  434,\n",
       "  579,\n",
       "  596,\n",
       "  435,\n",
       "  81,\n",
       "  334,\n",
       "  181,\n",
       "  6,\n",
       "  467,\n",
       "  635],\n",
       " '4': [348,\n",
       "  373,\n",
       "  191,\n",
       "  101,\n",
       "  116,\n",
       "  59,\n",
       "  383,\n",
       "  517,\n",
       "  506,\n",
       "  350,\n",
       "  376,\n",
       "  460,\n",
       "  35,\n",
       "  97,\n",
       "  650,\n",
       "  119,\n",
       "  662,\n",
       "  10,\n",
       "  359],\n",
       " '5': [542,\n",
       "  241,\n",
       "  155,\n",
       "  218,\n",
       "  196,\n",
       "  82,\n",
       "  532,\n",
       "  524,\n",
       "  31,\n",
       "  294,\n",
       "  110,\n",
       "  578,\n",
       "  137,\n",
       "  476,\n",
       "  358,\n",
       "  552,\n",
       "  262,\n",
       "  553],\n",
       " '6': [483,\n",
       "  519,\n",
       "  377,\n",
       "  395,\n",
       "  481,\n",
       "  -1,\n",
       "  146,\n",
       "  563,\n",
       "  29,\n",
       "  25,\n",
       "  539,\n",
       "  114,\n",
       "  522,\n",
       "  501,\n",
       "  474,\n",
       "  440,\n",
       "  351,\n",
       "  275],\n",
       " '7': [629,\n",
       "  365,\n",
       "  640,\n",
       "  623,\n",
       "  175,\n",
       "  64,\n",
       "  46,\n",
       "  617,\n",
       "  341,\n",
       "  426,\n",
       "  94,\n",
       "  280,\n",
       "  231,\n",
       "  225,\n",
       "  393,\n",
       "  385,\n",
       "  560,\n",
       "  297],\n",
       " '8': [293,\n",
       "  270,\n",
       "  369,\n",
       "  413,\n",
       "  477,\n",
       "  240,\n",
       "  611,\n",
       "  199,\n",
       "  52,\n",
       "  641,\n",
       "  131,\n",
       "  390,\n",
       "  333,\n",
       "  441,\n",
       "  322,\n",
       "  227,\n",
       "  463,\n",
       "  592],\n",
       " '9': [123,\n",
       "  188,\n",
       "  39,\n",
       "  200,\n",
       "  265,\n",
       "  403,\n",
       "  7,\n",
       "  320,\n",
       "  325,\n",
       "  274,\n",
       "  234,\n",
       "  602,\n",
       "  77,\n",
       "  331,\n",
       "  397,\n",
       "  223]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join('001_EDA', f'group_kfold_{group_col}.json'), 'r') as f:\n",
    "    fold = json.load(f)\n",
    "fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ea57203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_predict(X_train: pd.DataFrame,\n",
    "                           X_valid: pd.DataFrame,\n",
    "                           X_test: pd.DataFrame,\n",
    "                           y_train: np.ndarray,\n",
    "                           y_valid: np.ndarray,\n",
    "                           clf,\n",
    "                           fit_params: dict = None) -> tuple:\n",
    "    if fit_params is None:\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "    else:\n",
    "        clf = clf.fit(X_train, y_train, **fit_params)\n",
    "    pred_train = clf.predict(X_train)\n",
    "    print(f'train score: {f1_score(y_train, pred_train, average=\"macro\"):.5f}')\n",
    "    pred_valid = clf.predict(X_valid)\n",
    "    print(f'valid score: {f1_score(y_valid, pred_valid, average=\"macro\"):.5f}')\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "        proba_train = pd.DataFrame(data=clf.predict_proba(X_train), columns=clf.classes_)\n",
    "        proba_valid = pd.DataFrame(data=clf.predict_proba(X_valid), columns=clf.classes_)\n",
    "        proba_test = pd.DataFrame(data=clf.predict_proba(X_test), columns=clf.classes_)\n",
    "    else:\n",
    "        proba_train = pd.DataFrame(data=clf.decision_function(X_train), columns=clf.classes_)\n",
    "        proba_valid = pd.DataFrame(data=clf.decision_function(X_valid), columns=clf.classes_)\n",
    "        proba_test = pd.DataFrame(data=clf.decision_function(X_test), columns=clf.classes_)\n",
    "    return clf, proba_train, proba_valid, proba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6d569a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:05:44.525029Z",
     "iopub.status.busy": "2021-06-09T13:05:44.525029Z",
     "iopub.status.idle": "2021-06-09T13:13:28.713588Z",
     "shell.execute_reply": "2021-06-09T13:13:28.714590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.43799\n",
      "valid score: 0.14808\n",
      "XGBClassifier\n",
      "[04:39:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train score: 0.52134\n",
      "valid score: 0.14696\n",
      "svc1\n",
      "train score: 0.32996\n",
      "valid score: 0.17896\n",
      "svc10\n",
      "train score: 0.52863\n",
      "valid score: 0.17083\n",
      "knn\n",
      "train score: 0.21364\n",
      "valid score: 0.13444\n",
      "Final classifier\n",
      "**********Confusion matrix for train set (Fold 1)**********\n",
      "[[3471  758  698  450  197   56    7   41]\n",
      " [ 499 2900  379  215  111   27    7   22]\n",
      " [ 283  203 1850  181   91   27    2   19]\n",
      " [  89   54  109 1611   37    4    1    0]\n",
      " [   0    2    2    1  607    1    0    0]\n",
      " [   0    0    0    0    0  172    0    0]\n",
      " [   0    0    0    0    0    0   10    0]\n",
      " [   0    0    0    0    0    0    0  104]]\n",
      "\n",
      "train score: 0.692440\n",
      "**********Confusion matrix for validation set (Fold 1)**********\n",
      "[[270 204  75 103   3   0   0   0]\n",
      " [167 209  87  59   0   0   0   0]\n",
      " [117  77  53  86   3   0   0   0]\n",
      " [ 81  53  35  61   1   0   0   0]\n",
      " [ 20  18   7  17   0   0   0   0]\n",
      " [  6   4   2   3   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0]\n",
      " [  3   5   2   5   1   0   0   0]]\n",
      "\n",
      "valid score: 0.148170\n",
      "LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.44518\n",
      "valid score: 0.15706\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:34:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score: 0.50787\n",
      "valid score: 0.16639\n",
      "svc1\n",
      "train score: 0.32710\n",
      "valid score: 0.15464\n",
      "svc10\n",
      "train score: 0.52192\n",
      "valid score: 0.15188\n",
      "knn\n",
      "train score: 0.21425\n",
      "valid score: 0.13408\n",
      "Final classifier\n",
      "**********Confusion matrix for train set (Fold 2)**********\n",
      "[[3465  755  640  400  186   57   11   39]\n",
      " [ 485 2894  379  206   86   30    6   21]\n",
      " [ 276  179 1849  172  102   27    2   20]\n",
      " [  79   61  102 1581   30    4    2    2]\n",
      " [   1    1    1    1  582    2    0    0]\n",
      " [   0    0    0    0    0  168    0    0]\n",
      " [   0    0    0    0    0    0   10    0]\n",
      " [   0    0    0    0    0    0    0  107]]\n",
      "\n",
      "train score: 0.690441\n",
      "**********Confusion matrix for validation set (Fold 2)**********\n",
      "[[373 199  84 123   1   0   0   0]\n",
      " [220 209  58  85   3   0   0   0]\n",
      " [127  84  50 101   3   0   0   0]\n",
      " [ 91  50  44  83   7   0   0   0]\n",
      " [ 27  18  13  28   1   0   0   0]\n",
      " [  5   8   2   4   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0]\n",
      " [  6   3   3   1   0   0   0   0]]\n",
      "\n",
      "valid score: 0.155090\n",
      "LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.43873\n",
      "valid score: 0.15745\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:28:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score: 0.50057\n",
      "valid score: 0.16073\n",
      "svc1\n",
      "train score: 0.32854\n",
      "valid score: 0.15004\n",
      "svc10\n",
      "train score: 0.51762\n",
      "valid score: 0.16341\n",
      "knn\n",
      "train score: 0.21403\n",
      "valid score: 0.13448\n",
      "Final classifier\n",
      "**********Confusion matrix for train set (Fold 3)**********\n",
      "[[3455  761  711  442  193   60    7   42]\n",
      " [ 472 2891  398  201   97   30    5   27]\n",
      " [ 306  188 1776  200  104   25    1   18]\n",
      " [  94   68   96 1577   34    3    2    3]\n",
      " [   0    0    2    0  590    1    0    0]\n",
      " [   0    0    0    0    0  163    0    0]\n",
      " [   0    0    0    0    0    0    9    0]\n",
      " [   0    0    0    0    0    0    0  108]]\n",
      "\n",
      "train score: 0.686980\n",
      "**********Confusion matrix for validation set (Fold 3)**********\n",
      "[[291 185  86 100   0   0   0   0]\n",
      " [156 233  92  80   0   0   0   0]\n",
      " [128  91  66  88   1   0   0   0]\n",
      " [ 88  45  40  86   0   0   0   0]\n",
      " [ 26  13  16  26   1   0   0   0]\n",
      " [  3  10   3   8   0   0   0   0]\n",
      " [  2   0   0   0   0   0   0   0]\n",
      " [  4   5   2   1   0   0   0   0]]\n",
      "\n",
      "valid score: 0.164911\n",
      "LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.44070\n",
      "valid score: 0.14431\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:07:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score: 0.50843\n",
      "valid score: 0.15524\n",
      "svc1\n",
      "train score: 0.32562\n",
      "valid score: 0.16119\n",
      "svc10\n",
      "train score: 0.52465\n",
      "valid score: 0.14927\n",
      "knn\n",
      "train score: 0.21382\n",
      "valid score: 0.12843\n",
      "Final classifier\n",
      "**********Confusion matrix for train set (Fold 4)**********\n",
      "[[3458  763  716  413  206   62    8   41]\n",
      " [ 479 2985  389  201  101   26    5   24]\n",
      " [ 292  187 1841  200  102   24    1   16]\n",
      " [  82   61  105 1629   34    4    1    2]\n",
      " [   1    0    2    1  601    1    0    0]\n",
      " [   0    0    0    0    0  156    0    0]\n",
      " [   0    0    0    0    0    0   10    0]\n",
      " [   0    0    0    0    0    0    0  106]]\n",
      "\n",
      "train score: 0.694683\n",
      "**********Confusion matrix for validation set (Fold 4)**********\n",
      "[[262 167 107 127   3   0   0   0]\n",
      " [135 192  76  68   1   0   0   0]\n",
      " [ 96  75  64  93   1   0   0   0]\n",
      " [ 69  51  42  55   1   0   0   0]\n",
      " [ 23  14  17  15   0   0   0   0]\n",
      " [ 10   5   4  11   1   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0]\n",
      " [  3   5   2   4   0   0   0   0]]\n",
      "\n",
      "valid score: 0.148926\n",
      "LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.43703\n",
      "valid score: 0.15505\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:01:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score: 0.51760\n",
      "valid score: 0.16004\n",
      "svc1\n",
      "train score: 0.32722\n",
      "valid score: 0.15210\n",
      "svc10\n",
      "train score: 0.51901\n",
      "valid score: 0.14578\n",
      "knn\n",
      "train score: 0.21544\n",
      "valid score: 0.12956\n",
      "Final classifier\n",
      "**********Confusion matrix for train set (Fold 5)**********\n",
      "[[3501  768  748  410  217   49    9   40]\n",
      " [ 551 2959  379  207  120   28    7   25]\n",
      " [ 306  191 1908  187  107   25    1   19]\n",
      " [  90   67   95 1649   36    4    2    1]\n",
      " [   1    0    1    1  616    1    0    0]\n",
      " [   0    0    0    0    0  170    0    0]\n",
      " [   0    0    0    0    0    0   10    0]\n",
      " [   0    0    0    0    0    0    0  110]]\n",
      "\n",
      "train score: 0.689448\n",
      "**********Confusion matrix for validation set (Fold 5)**********\n",
      "[[292 176  60  59   4   0   0   0]\n",
      " [143 165  44  52   2   0   0   0]\n",
      " [ 85  74  32  56   1   0   0   0]\n",
      " [ 75  53  30  32   2   0   0   0]\n",
      " [ 17  13  14  11   0   0   0   0]\n",
      " [  7   4   3   3   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0]\n",
      " [  2   2   4   2   0   0   0   0]]\n",
      "\n",
      "valid score: 0.144419\n",
      "LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.43939\n",
      "valid score: 0.15451\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:23:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score: 0.52256\n",
      "valid score: 0.16323\n",
      "svc1\n",
      "train score: 0.33128\n",
      "valid score: 0.15602\n",
      "svc10\n",
      "train score: 0.51928\n",
      "valid score: 0.15710\n",
      "knn\n",
      "train score: 0.21495\n",
      "valid score: 0.12767\n",
      "Final classifier\n",
      "**********Confusion matrix for train set (Fold 6)**********\n",
      "[[3448  734  756  424  191   60   10   45]\n",
      " [ 519 2918  372  228  111   30    6   22]\n",
      " [ 308  193 1890  170   80   24    1   19]\n",
      " [  89   68   87 1635   42    3    2    1]\n",
      " [   1    2    1    1  595    0    0    0]\n",
      " [   0    0    0    0    0  166    0    0]\n",
      " [   0    0    0    0    0    0   10    0]\n",
      " [   0    0    0    0    0    0    0  110]]\n",
      "\n",
      "train score: 0.688537\n",
      "**********Confusion matrix for validation set (Fold 6)**********\n",
      "[[281 227  86  66   5   0   0   0]\n",
      " [162 185  75  54   0   0   0   0]\n",
      " [ 91  92  61  58   5   0   0   0]\n",
      " [ 59  62  37  50   1   0   0   0]\n",
      " [ 24  19  12  19   1   0   0   0]\n",
      " [  7   7   3   3   1   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0]\n",
      " [  3   3   2   2   0   0   0   0]]\n",
      "\n",
      "valid score: 0.153612\n",
      "LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.44705\n",
      "valid score: 0.15711\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:18:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score: 0.51919\n",
      "valid score: 0.16577\n",
      "svc1\n",
      "train score: 0.33409\n",
      "valid score: 0.15813\n",
      "svc10\n",
      "train score: 0.52462\n",
      "valid score: 0.16367\n",
      "knn\n",
      "train score: 0.21742\n",
      "valid score: 0.14763\n",
      "Final classifier\n",
      "**********Confusion matrix for train set (Fold 7)**********\n",
      "[[3495  711  699  404  180   47    8   41]\n",
      " [ 521 2846  395  192   99   27    7   23]\n",
      " [ 298  196 1846  189   92   25    2   16]\n",
      " [  85   64   91 1595   30    5    2    2]\n",
      " [   1    1    2    1  598    1    0    0]\n",
      " [   0    0    0    0    0  171    0    0]\n",
      " [   0    0    0    0    0    0   10    0]\n",
      " [   0    0    0    0    0    0    0  107]]\n",
      "\n",
      "train score: 0.695347\n",
      "**********Confusion matrix for validation set (Fold 7)**********\n",
      "[[354 201  84 109   0   0   0   0]\n",
      " [216 207  68  81   0   0   0   0]\n",
      " [129  72  56  71   0   0   0   0]\n",
      " [ 88  56  41  77   0   0   0   0]\n",
      " [ 28  14  11  18   0   0   0   0]\n",
      " [  6   5   4   1   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0]\n",
      " [  9   3   1   0   0   0   0   0]]\n",
      "\n",
      "valid score: 0.156548\n",
      "LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.43913\n",
      "valid score: 0.15649\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:50:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score: 0.50722\n",
      "valid score: 0.15884\n",
      "svc1\n",
      "train score: 0.32988\n",
      "valid score: 0.17255\n",
      "svc10\n",
      "train score: 0.52352\n",
      "valid score: 0.15686\n",
      "knn\n",
      "train score: 0.21308\n",
      "valid score: 0.12867\n",
      "Final classifier\n",
      "**********Confusion matrix for train set (Fold 8)**********\n",
      "[[3497  759  739  427  182   49    8   35]\n",
      " [ 516 2948  405  229   96   27    6   26]\n",
      " [ 321  198 1842  204   91   26    1   21]\n",
      " [  91   71  112 1617   42    6    2    2]\n",
      " [   1    1    1    2  587    1    0    0]\n",
      " [   0    0    0    0    0  169    0    0]\n",
      " [   0    0    0    0    0    0   10    0]\n",
      " [   0    0    0    0    0    0    0  107]]\n",
      "\n",
      "train score: 0.690784\n",
      "**********Confusion matrix for validation set (Fold 8)**********\n",
      "[[285 194  89  68   1   0   0   0]\n",
      " [163 181  58  26   1   0   0   0]\n",
      " [105  78  44  56   5   0   0   0]\n",
      " [ 82  32  42  36   1   0   0   0]\n",
      " [ 28  22  15  17   0   0   0   0]\n",
      " [  9   3   4   2   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0]\n",
      " [  5   7   1   0   0   0   0   0]]\n",
      "\n",
      "valid score: 0.144965\n",
      "LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.44540\n",
      "valid score: 0.15521\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:51:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score: 0.51049\n",
      "valid score: 0.16328\n",
      "svc1\n",
      "train score: 0.33281\n",
      "valid score: 0.17004\n",
      "svc10\n",
      "train score: 0.52352\n",
      "valid score: 0.15232\n",
      "knn\n",
      "train score: 0.21413\n",
      "valid score: 0.13245\n",
      "Final classifier\n",
      "**********Confusion matrix for train set (Fold 9)**********\n",
      "[[3470  795  760  467  215   57    8   48]\n",
      " [ 512 3039  400  222   93   32    6   26]\n",
      " [ 329  206 1904  193   99   23    2   17]\n",
      " [  87   73  100 1677   36    4    2    2]\n",
      " [   1    0    2    1  618    1    0    0]\n",
      " [   0    0    0    0    0  175    0    0]\n",
      " [   0    0    0    0    0    0   10    0]\n",
      " [   0    0    0    0    0    0    0  110]]\n",
      "\n",
      "train score: 0.686428\n",
      "**********Confusion matrix for validation set (Fold 9)**********\n",
      "[[252 129  82  50   0   0   0   0]\n",
      " [151 123  42  36   0   0   0   0]\n",
      " [ 87  50  52  30   0   0   0   0]\n",
      " [ 49  39  35  32   0   0   0   0]\n",
      " [ 20  10  13   9   0   0   0   0]\n",
      " [  6   0   4   2   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0]\n",
      " [  3   3   2   2   0   0   0   0]]\n",
      "\n",
      "valid score: 0.156050\n",
      "LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.43777\n",
      "valid score: 0.15763\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nndropout\\miniconda3\\envs\\ds\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score: 0.52417\n",
      "valid score: 0.17082\n",
      "svc1\n",
      "train score: 0.32554\n",
      "valid score: 0.18036\n",
      "svc10\n",
      "train score: 0.51886\n",
      "valid score: 0.16089\n",
      "knn\n",
      "train score: 0.21335\n",
      "valid score: 0.13358\n",
      "Final classifier\n",
      "**********Confusion matrix for train set (Fold 10)**********\n",
      "[[3545  847  751  459  214   53    6   42]\n",
      " [ 561 3033  392  200  114   30    6   29]\n",
      " [ 320  207 1936  193   95   24    2   17]\n",
      " [ 107   71   93 1679   40    2    1    1]\n",
      " [   1    3    3    2  626    0    0    0]\n",
      " [   0    0    0    0    0  173    0    0]\n",
      " [   0    0    0    0    0    0   10    0]\n",
      " [   0    0    0    0    0    0    0  111]]\n",
      "\n",
      "train score: 0.694030\n",
      "**********Confusion matrix for validation set (Fold 10)**********\n",
      "[[200 100  49  67   0   0   0   0]\n",
      " [108 112  44  52   1   0   0   0]\n",
      " [ 72  32  37  56   1   0   0   0]\n",
      " [ 50  30  19  43   0   0   0   0]\n",
      " [ 13   9  10   7   1   0   0   0]\n",
      " [  7   5   0   2   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0]\n",
      " [  3   1   5   0   0   0   0   0]]\n",
      "\n",
      "valid score: 0.164165\n",
      "Wall time: 20h 18min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# splitter = StratifiedKFold(shuffle=True, random_state=SEED, n_splits=N)\n",
    "cv_pred_dfs = []\n",
    "pred_dfs = []\n",
    "metrics = {'train': [], 'valid': []}\n",
    "models = []\n",
    "# for i, (train_idx, valid_idx) in enumerate(splitter.split(train, train.y)):\n",
    "for str_i, ids in fold.items():\n",
    "    i = int(str_i)\n",
    "    mask = groups.isin(ids)  # training/validation = False/True\n",
    "    train_idx, id_train, X_train, y_train, valid_idx, id_valid, X_valid, y_valid = (\n",
    "        train[~mask].index,\n",
    "        train[~mask].id,\n",
    "        train[~mask][features],\n",
    "        train[~mask].y,\n",
    "        train[mask].index,\n",
    "        train[mask].id,\n",
    "        train[mask][features],\n",
    "        train[mask].y,\n",
    "    )\n",
    "    proba_train = pd.DataFrame()\n",
    "    proba_valid = pd.DataFrame()\n",
    "    proba_test = pd.DataFrame()\n",
    "    \n",
    "    # Feature engineering for tree models\n",
    "    X_train_transformed1 = X_train[discrete_features + categorical_features]\n",
    "    X_valid_transformed1 = X_valid[discrete_features + categorical_features]\n",
    "    X_test_transformed1 = test[discrete_features + categorical_features]\n",
    "\n",
    "    # train LGBMClassifier and get probability prediction\n",
    "    print('LGBMClassifier')\n",
    "    clf_lgbm = LGBMClassifier(objective='multiclass',\n",
    "                              importance_type='gain',\n",
    "                              n_jobs=-1,\n",
    "                              class_weight='balanced',\n",
    "                              n_estimators=300,\n",
    "                              learning_rate=0.01,\n",
    "                              boosting_type='gbdt',\n",
    "                              num_leaves=32,\n",
    "                              random_state=SEED,\n",
    "                              reg_alpha=0.05)\n",
    "    clf_lgbm, proba_train_lgbm, proba_valid_lgbm, proba_test_lgbm = \\\n",
    "        train_evaluate_predict(X_train=X_train_transformed1,\n",
    "                               X_valid=X_valid_transformed1,\n",
    "                               X_test=X_test_transformed1,\n",
    "                               y_train=y_train.values,\n",
    "                               y_valid=y_valid.values,\n",
    "                               clf=clf_lgbm,\n",
    "                               fit_params={'categorical_feature': categorical_features})\n",
    "    proba_train_lgbm.columns = [f'lgbm{c}' for c in proba_train_lgbm.columns]\n",
    "    proba_valid_lgbm.columns = [f'lgbm{c}' for c in proba_valid_lgbm.columns]\n",
    "    proba_test_lgbm.columns = [f'lgbm{c}' for c in proba_test_lgbm.columns]\n",
    "    proba_train = pd.concat([proba_train, proba_train_lgbm], axis=1)\n",
    "    proba_valid = pd.concat([proba_valid, proba_valid_lgbm], axis=1)\n",
    "    proba_test = pd.concat([proba_test, proba_test_lgbm], axis=1)\n",
    "\n",
    "    # train XGBClassifier and get probability prediction\n",
    "    print('XGBClassifier')\n",
    "    class_weight = compute_class_weight('balanced',\n",
    "                                        classes=np.sort(train.y.unique()),\n",
    "                                        y=y_train.values)\n",
    "    class_weight = dict(\n",
    "        zip(\n",
    "            np.sort(train.y.unique()),\n",
    "            class_weight\n",
    "        )\n",
    "    )\n",
    "    sample_weight = y_train.map(class_weight)\n",
    "    assert(sample_weight.isnull().sum() == 0)\n",
    "    clf_xgb = XGBClassifier(n_jobs=-1,\n",
    "                            n_estimators=300,\n",
    "                            max_depth=9,\n",
    "                            learning_rate=0.01,\n",
    "                            random_state=SEED)\n",
    "    clf_xgb, proba_train_xgb, proba_valid_xgb, proba_test_xgb = \\\n",
    "        train_evaluate_predict(X_train=X_train_transformed1,\n",
    "                               X_valid=X_valid_transformed1,\n",
    "                               X_test=X_test_transformed1,\n",
    "                               y_train=y_train.values,\n",
    "                               y_valid=y_valid.values,\n",
    "                               clf=clf_xgb,\n",
    "                               fit_params={'sample_weight': sample_weight})\n",
    "    proba_train_xgb.columns = [f'xgb{c}' for c in proba_train_xgb.columns]\n",
    "    proba_valid_xgb.columns = [f'xgb{c}' for c in proba_valid_xgb.columns]\n",
    "    proba_test_xgb.columns = [f'xgb{c}' for c in proba_test_xgb.columns]\n",
    "    proba_train = pd.concat([proba_train, proba_train_xgb], axis=1)\n",
    "    proba_valid = pd.concat([proba_valid, proba_valid_xgb], axis=1)\n",
    "    proba_test = pd.concat([proba_test, proba_test_xgb], axis=1)\n",
    "    # Feature engineering for other models\n",
    "    ## transform categorical features one hot style\n",
    "    temp_col = 'where__'\n",
    "#     assert(temp_col not in X_train and temp_col not in X_valid and temp_col not in test)\n",
    "    X_train[temp_col] = 'train'\n",
    "    X_valid[temp_col] = 'valid'\n",
    "    test[temp_col] = 'test'\n",
    "    X_categories = pd.concat(\n",
    "        [\n",
    "            X_train[categorical_features + [temp_col]],\n",
    "            X_valid[categorical_features + [temp_col]],\n",
    "            test[categorical_features + [temp_col]]\n",
    "        ],\n",
    "        axis=0\n",
    "    )\n",
    "    X_onehot = pd.get_dummies(X_categories, columns=categorical_features, drop_first=True)\n",
    "    one_hot_features = [c for c in X_onehot if c != temp_col]\n",
    "    X_train_onehot = X_onehot.query(f'{temp_col} == \"train\"')[one_hot_features].reset_index(drop=True)\n",
    "    X_valid_onehot = X_onehot.query(f'{temp_col} == \"valid\"')[one_hot_features].reset_index(drop=True)\n",
    "    X_test_onehot = X_onehot.query(f'{temp_col} == \"test\"')[one_hot_features].reset_index(drop=True)\n",
    "    ## scale discrete features\n",
    "    scaler = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]).fit(X_train[discrete_features])\n",
    "    X_train_discrete = pd.DataFrame(\n",
    "        data=scaler.transform(X_train[discrete_features]),\n",
    "        columns=discrete_features\n",
    "    ).reset_index(drop=True)\n",
    "    X_valid_discrete = pd.DataFrame(\n",
    "        data=scaler.transform(X_valid[discrete_features]),\n",
    "        columns=discrete_features\n",
    "    ).reset_index(drop=True)\n",
    "    X_test_discrete = pd.DataFrame(\n",
    "        data=scaler.transform(test[discrete_features]),\n",
    "        columns=discrete_features\n",
    "    ).reset_index(drop=True)\n",
    "    ## merge\n",
    "    X_train_transformed2 = pd.concat([X_train_discrete, X_train_onehot], axis=1)\n",
    "    X_valid_transformed2 = pd.concat([X_valid_discrete, X_valid_onehot], axis=1)\n",
    "    X_test_transformed2 = pd.concat([X_test_discrete, X_test_onehot], axis=1)\n",
    "    \n",
    "    other_classifiers = {\n",
    "        'svc1': SVC(C=1., random_state=SEED, class_weight='balanced'),\n",
    "        'svc10': SVC(C=10., random_state=SEED, class_weight='balanced'),\n",
    "        'knn': KNN(n_jobs=-1)\n",
    "    }\n",
    "    for name, clf_ in other_classifiers.items():\n",
    "        print(name)\n",
    "        clf_, proba_train_, proba_valid_, proba_test_ = \\\n",
    "            train_evaluate_predict(X_train=X_train_transformed2,\n",
    "                                   X_valid=X_valid_transformed2,\n",
    "                                   X_test=X_test_transformed2,\n",
    "                                   y_train=y_train.values,\n",
    "                                   y_valid=y_valid.values,\n",
    "                                   clf=clf_)\n",
    "        proba_train_.columns = [f'{name}{c}' for c in proba_train_.columns]\n",
    "        proba_valid_.columns = [f'{name}{c}' for c in proba_valid_.columns]\n",
    "        proba_test_.columns = [f'{name}{c}' for c in proba_test_.columns]\n",
    "        proba_train = pd.concat([proba_train, proba_train_], axis=1)\n",
    "        proba_valid = pd.concat([proba_valid, proba_valid_], axis=1)\n",
    "        proba_test = pd.concat([proba_test, proba_test_], axis=1)\n",
    "\n",
    "    # blending\n",
    "    print('Final classifier')\n",
    "    clf = LogisticRegression(random_state=SEED, n_jobs=-1, class_weight='balanced', max_iter=1000)\n",
    "    clf.fit(proba_train, y_train.values)\n",
    "    clf.feature_names__ = proba_train.columns.tolist()\n",
    "    with open(os.path.join(OUTPUT_DIR, f'model_fold{i + 1}.pickle'), 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "        f.close()\n",
    "    models.append(clf)\n",
    "    # Evaluate (trian set)\n",
    "    pred_train = clf.predict(proba_train)\n",
    "    \n",
    "    if pred_train.ndim > 1:\n",
    "        pred_train = np.squeeze(pred_train)\n",
    "    pred_train_df = pd.DataFrame(\n",
    "        {\n",
    "            'id': id_train,\n",
    "            'actual': y_train,\n",
    "            'prediction': pred_train,\n",
    "        }\n",
    "    )\n",
    "    pred_train_df['train'] = 0\n",
    "    print('*' * 10 + f'Confusion matrix for train set (Fold {i + 1})' + '*' * 10)\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "    print()\n",
    "    metrics['train'].append(f1_score(y_train, pred_train, average='macro'))\n",
    "    print(f'train score: {f1_score(y_train, pred_train, average=\"macro\"):.6f}')\n",
    "    # Evaluate (valid set)\n",
    "    pred_valid = clf.predict(proba_valid)\n",
    "    if pred_valid.ndim > 1:\n",
    "        pred_valid = np.squeeze(pred_valid)\n",
    "    pred_valid_df = pd.DataFrame(\n",
    "        {\n",
    "            'id': id_valid,\n",
    "            'actual': y_valid,\n",
    "            'prediction': pred_valid,\n",
    "        }\n",
    "    )\n",
    "    pred_valid_df['train'] = 1\n",
    "    print('*' * 10 + f'Confusion matrix for validation set (Fold {i + 1})' + '*' * 10)\n",
    "    print(confusion_matrix(y_valid, pred_valid))\n",
    "    print()\n",
    "    metrics['valid'].append(f1_score(y_valid, pred_valid, average='macro'))\n",
    "    print(f'valid score: {f1_score(y_valid, pred_valid, average=\"macro\"):.6f}')\n",
    "    # Save cv result\n",
    "    cv_pred_df = pd.concat([pred_train_df, pred_valid_df], axis=0)\n",
    "    cv_pred_df['fold'] = i + 1\n",
    "    cv_pred_dfs.append(cv_pred_df)\n",
    "    # Inference\n",
    "    try:\n",
    "        infer = clf.predict_proba(proba_test)\n",
    "    except AttributeError:\n",
    "        infer = clf.decision_function(proba_test)\n",
    "    pred_df = pd.DataFrame(\n",
    "        data=infer,\n",
    "        columns=clf.classes_\n",
    "    )\n",
    "    pred_df['id'] = test.id.values\n",
    "    pred_df['fold'] = i + 1\n",
    "    pred_dfs.append(pred_df)\n",
    "    \n",
    "    proba_train['id'] = id_train\n",
    "    proba_valid['id'] = id_valid\n",
    "    proba_test['id'] = test.id\n",
    "    proba_train.to_csv(os.path.join(OUTPUT_DIR, f'train_features_fold{i + 1}.csv'), index=False)\n",
    "    proba_valid.to_csv(os.path.join(OUTPUT_DIR, f'valid_features_fold{i + 1}.csv'), index=False)\n",
    "    proba_test.to_csv(os.path.join(OUTPUT_DIR, f'test_features_fold{i + 1}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb89725e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:13:28.724588Z",
     "iopub.status.busy": "2021-06-09T13:13:28.718589Z",
     "iopub.status.idle": "2021-06-09T13:13:28.744590Z",
     "shell.execute_reply": "2021-06-09T13:13:28.745591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.690912</td>\n",
       "      <td>0.153686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.686428</td>\n",
       "      <td>0.144419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.688765</td>\n",
       "      <td>0.148359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.690612</td>\n",
       "      <td>0.154351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.693633</td>\n",
       "      <td>0.156423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.695347</td>\n",
       "      <td>0.164911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train      valid\n",
       "count  10.000000  10.000000\n",
       "mean    0.690912   0.153686\n",
       "std     0.003154   0.007200\n",
       "min     0.686428   0.144419\n",
       "25%     0.688765   0.148359\n",
       "50%     0.690612   0.154351\n",
       "75%     0.693633   0.156423\n",
       "max     0.695347   0.164911"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(metrics).describe()\n",
    "metrics.to_csv(os.path.join(OUTPUT_DIR, 'metrics.csv'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "691d13f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:13:28.749590Z",
     "iopub.status.busy": "2021-06-09T13:13:28.748588Z",
     "iopub.status.idle": "2021-06-09T13:13:29.000158Z",
     "shell.execute_reply": "2021-06-09T13:13:28.999111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>train</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17075</th>\n",
       "      <td>1431</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17076</th>\n",
       "      <td>1432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17077</th>\n",
       "      <td>1433</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17078</th>\n",
       "      <td>1434</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17079</th>\n",
       "      <td>1435</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171360 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  actual  prediction  train  fold\n",
       "0         0       0           0      0     1\n",
       "1         1       1           0      0     1\n",
       "2         2       0           0      0     1\n",
       "3         3       2           2      0     1\n",
       "4         4       4           4      0     1\n",
       "...     ...     ...         ...    ...   ...\n",
       "17075  1431       1           1      1    10\n",
       "17076  1432       0           0      1    10\n",
       "17077  1433       1           3      1    10\n",
       "17078  1434       2           3      1    10\n",
       "17079  1435       3           3      1    10\n",
       "\n",
       "[171360 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.concat(cv_pred_dfs)\n",
    "cv_results.to_csv(os.path.join(OUTPUT_DIR, 'cross_validation.csv'), index=False)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4ba528d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:13:29.004112Z",
     "iopub.status.busy": "2021-06-09T13:13:29.003123Z",
     "iopub.status.idle": "2021-06-09T13:13:29.030125Z",
     "shell.execute_reply": "2021-06-09T13:13:29.030125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>id</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.154508</td>\n",
       "      <td>0.570508</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>1.848815e-01</td>\n",
       "      <td>1.186931e-09</td>\n",
       "      <td>5.230663e-14</td>\n",
       "      <td>2.737019e-07</td>\n",
       "      <td>27446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.400794</td>\n",
       "      <td>0.093885</td>\n",
       "      <td>0.410854</td>\n",
       "      <td>0.094457</td>\n",
       "      <td>9.429457e-06</td>\n",
       "      <td>4.858775e-09</td>\n",
       "      <td>4.919753e-14</td>\n",
       "      <td>2.650757e-08</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060931</td>\n",
       "      <td>0.069090</td>\n",
       "      <td>0.863512</td>\n",
       "      <td>0.006467</td>\n",
       "      <td>5.652902e-07</td>\n",
       "      <td>1.102511e-09</td>\n",
       "      <td>2.722605e-15</td>\n",
       "      <td>4.561709e-09</td>\n",
       "      <td>4479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011325</td>\n",
       "      <td>0.007788</td>\n",
       "      <td>0.956478</td>\n",
       "      <td>0.024409</td>\n",
       "      <td>7.306847e-07</td>\n",
       "      <td>2.332197e-10</td>\n",
       "      <td>5.771630e-16</td>\n",
       "      <td>1.055386e-08</td>\n",
       "      <td>29080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.106157</td>\n",
       "      <td>0.705915</td>\n",
       "      <td>0.056121</td>\n",
       "      <td>5.857942e-06</td>\n",
       "      <td>7.350039e-08</td>\n",
       "      <td>2.129002e-14</td>\n",
       "      <td>4.518531e-08</td>\n",
       "      <td>19319</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33803</th>\n",
       "      <td>0.027291</td>\n",
       "      <td>0.950550</td>\n",
       "      <td>0.020874</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>1.972449e-08</td>\n",
       "      <td>2.137550e-11</td>\n",
       "      <td>1.937487e-15</td>\n",
       "      <td>4.069044e-10</td>\n",
       "      <td>24272</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33804</th>\n",
       "      <td>0.041816</td>\n",
       "      <td>0.930835</td>\n",
       "      <td>0.026473</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>2.020728e-06</td>\n",
       "      <td>4.072223e-11</td>\n",
       "      <td>7.406282e-13</td>\n",
       "      <td>5.751670e-10</td>\n",
       "      <td>29106</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33805</th>\n",
       "      <td>0.050280</td>\n",
       "      <td>0.928508</td>\n",
       "      <td>0.019149</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>2.740847e-06</td>\n",
       "      <td>4.042827e-11</td>\n",
       "      <td>2.222463e-12</td>\n",
       "      <td>5.759417e-10</td>\n",
       "      <td>20679</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33806</th>\n",
       "      <td>0.376108</td>\n",
       "      <td>0.267763</td>\n",
       "      <td>0.343602</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>6.637260e-06</td>\n",
       "      <td>1.136341e-10</td>\n",
       "      <td>4.861858e-12</td>\n",
       "      <td>1.408585e-09</td>\n",
       "      <td>25901</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33807</th>\n",
       "      <td>0.128076</td>\n",
       "      <td>0.849145</td>\n",
       "      <td>0.020495</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>4.954677e-07</td>\n",
       "      <td>5.429145e-11</td>\n",
       "      <td>6.076524e-15</td>\n",
       "      <td>2.945889e-10</td>\n",
       "      <td>12497</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338080 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3             4             5  \\\n",
       "0      0.081967  0.154508  0.570508  0.008135  1.848815e-01  1.186931e-09   \n",
       "1      0.400794  0.093885  0.410854  0.094457  9.429457e-06  4.858775e-09   \n",
       "2      0.060931  0.069090  0.863512  0.006467  5.652902e-07  1.102511e-09   \n",
       "3      0.011325  0.007788  0.956478  0.024409  7.306847e-07  2.332197e-10   \n",
       "4      0.131800  0.106157  0.705915  0.056121  5.857942e-06  7.350039e-08   \n",
       "...         ...       ...       ...       ...           ...           ...   \n",
       "33803  0.027291  0.950550  0.020874  0.001285  1.972449e-08  2.137550e-11   \n",
       "33804  0.041816  0.930835  0.026473  0.000874  2.020728e-06  4.072223e-11   \n",
       "33805  0.050280  0.928508  0.019149  0.002061  2.740847e-06  4.042827e-11   \n",
       "33806  0.376108  0.267763  0.343602  0.012520  6.637260e-06  1.136341e-10   \n",
       "33807  0.128076  0.849145  0.020495  0.002283  4.954677e-07  5.429145e-11   \n",
       "\n",
       "                  6             7     id  fold  \n",
       "0      5.230663e-14  2.737019e-07  27446     1  \n",
       "1      4.919753e-14  2.650757e-08    113     1  \n",
       "2      2.722605e-15  4.561709e-09   4479     1  \n",
       "3      5.771630e-16  1.055386e-08  29080     1  \n",
       "4      2.129002e-14  4.518531e-08  19319     1  \n",
       "...             ...           ...    ...   ...  \n",
       "33803  1.937487e-15  4.069044e-10  24272    10  \n",
       "33804  7.406282e-13  5.751670e-10  29106    10  \n",
       "33805  2.222463e-12  5.759417e-10  20679    10  \n",
       "33806  4.861858e-12  1.408585e-09  25901    10  \n",
       "33807  6.076524e-15  2.945889e-10  12497    10  \n",
       "\n",
       "[338080 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ = pd.concat(pred_dfs)\n",
    "submission_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79a0c0ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:13:29.040137Z",
     "iopub.status.busy": "2021-06-09T13:13:29.040137Z",
     "iopub.status.idle": "2021-06-09T13:13:29.094111Z",
     "shell.execute_reply": "2021-06-09T13:13:29.095158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.819457</td>\n",
       "      <td>5.578425</td>\n",
       "      <td>3.357713</td>\n",
       "      <td>0.244383</td>\n",
       "      <td>2.157882e-05</td>\n",
       "      <td>1.479065e-08</td>\n",
       "      <td>1.863097e-10</td>\n",
       "      <td>1.605099e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.720541</td>\n",
       "      <td>3.546693</td>\n",
       "      <td>0.423448</td>\n",
       "      <td>0.309317</td>\n",
       "      <td>3.598138e-07</td>\n",
       "      <td>4.611904e-08</td>\n",
       "      <td>2.999032e-10</td>\n",
       "      <td>5.287230e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.131112</td>\n",
       "      <td>0.313633</td>\n",
       "      <td>0.301445</td>\n",
       "      <td>9.250581</td>\n",
       "      <td>3.044975e-03</td>\n",
       "      <td>1.014315e-08</td>\n",
       "      <td>2.657503e-08</td>\n",
       "      <td>1.845510e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.525217</td>\n",
       "      <td>5.632873</td>\n",
       "      <td>0.762354</td>\n",
       "      <td>0.079555</td>\n",
       "      <td>6.715158e-07</td>\n",
       "      <td>5.371278e-09</td>\n",
       "      <td>7.810772e-10</td>\n",
       "      <td>1.029124e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.745291</td>\n",
       "      <td>6.355201</td>\n",
       "      <td>0.464672</td>\n",
       "      <td>0.398726</td>\n",
       "      <td>3.611024e-02</td>\n",
       "      <td>3.457776e-08</td>\n",
       "      <td>1.318452e-09</td>\n",
       "      <td>3.632738e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33803</th>\n",
       "      <td>33803</td>\n",
       "      <td>8.449245</td>\n",
       "      <td>0.605091</td>\n",
       "      <td>0.527278</td>\n",
       "      <td>0.417942</td>\n",
       "      <td>4.427508e-04</td>\n",
       "      <td>2.186659e-08</td>\n",
       "      <td>2.467781e-09</td>\n",
       "      <td>2.942154e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33804</th>\n",
       "      <td>33804</td>\n",
       "      <td>5.529505</td>\n",
       "      <td>2.405217</td>\n",
       "      <td>0.475473</td>\n",
       "      <td>1.587440</td>\n",
       "      <td>2.364738e-03</td>\n",
       "      <td>4.958524e-09</td>\n",
       "      <td>3.787382e-10</td>\n",
       "      <td>4.003942e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33805</th>\n",
       "      <td>33805</td>\n",
       "      <td>2.195281</td>\n",
       "      <td>4.466306</td>\n",
       "      <td>1.837204</td>\n",
       "      <td>1.501207</td>\n",
       "      <td>2.246288e-07</td>\n",
       "      <td>1.243756e-09</td>\n",
       "      <td>2.434816e-09</td>\n",
       "      <td>1.679963e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33806</th>\n",
       "      <td>33806</td>\n",
       "      <td>1.642783</td>\n",
       "      <td>2.277561</td>\n",
       "      <td>5.408487</td>\n",
       "      <td>0.670123</td>\n",
       "      <td>1.045930e-03</td>\n",
       "      <td>3.387614e-08</td>\n",
       "      <td>1.058681e-09</td>\n",
       "      <td>1.641247e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33807</th>\n",
       "      <td>33807</td>\n",
       "      <td>6.826573</td>\n",
       "      <td>0.921803</td>\n",
       "      <td>0.446235</td>\n",
       "      <td>1.625875</td>\n",
       "      <td>1.795130e-01</td>\n",
       "      <td>7.199070e-08</td>\n",
       "      <td>8.995225e-09</td>\n",
       "      <td>2.292519e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33808 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         0         1         2         3             4  \\\n",
       "0          0  0.819457  5.578425  3.357713  0.244383  2.157882e-05   \n",
       "1          1  5.720541  3.546693  0.423448  0.309317  3.598138e-07   \n",
       "2          2  0.131112  0.313633  0.301445  9.250581  3.044975e-03   \n",
       "3          3  3.525217  5.632873  0.762354  0.079555  6.715158e-07   \n",
       "4          4  2.745291  6.355201  0.464672  0.398726  3.611024e-02   \n",
       "...      ...       ...       ...       ...       ...           ...   \n",
       "33803  33803  8.449245  0.605091  0.527278  0.417942  4.427508e-04   \n",
       "33804  33804  5.529505  2.405217  0.475473  1.587440  2.364738e-03   \n",
       "33805  33805  2.195281  4.466306  1.837204  1.501207  2.246288e-07   \n",
       "33806  33806  1.642783  2.277561  5.408487  0.670123  1.045930e-03   \n",
       "33807  33807  6.826573  0.921803  0.446235  1.625875  1.795130e-01   \n",
       "\n",
       "                  5             6             7  \n",
       "0      1.479065e-08  1.863097e-10  1.605099e-07  \n",
       "1      4.611904e-08  2.999032e-10  5.287230e-08  \n",
       "2      1.014315e-08  2.657503e-08  1.845510e-04  \n",
       "3      5.371278e-09  7.810772e-10  1.029124e-07  \n",
       "4      3.457776e-08  1.318452e-09  3.632738e-07  \n",
       "...             ...           ...           ...  \n",
       "33803  2.186659e-08  2.467781e-09  2.942154e-07  \n",
       "33804  4.958524e-09  3.787382e-10  4.003942e-07  \n",
       "33805  1.243756e-09  2.434816e-09  1.679963e-06  \n",
       "33806  3.387614e-08  1.058681e-09  1.641247e-07  \n",
       "33807  7.199070e-08  8.995225e-09  2.292519e-07  \n",
       "\n",
       "[33808 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ = submission_.groupby('id')[[0, 1, 2, 3, 4, 5, 6, 7]].sum().sort_index().reset_index()\n",
    "submission_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa1deefc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:13:29.099112Z",
     "iopub.status.busy": "2021-06-09T13:13:29.099112Z",
     "iopub.status.idle": "2021-06-09T13:13:29.110111Z",
     "shell.execute_reply": "2021-06-09T13:13:29.110111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33803</th>\n",
       "      <td>33803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33804</th>\n",
       "      <td>33804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33805</th>\n",
       "      <td>33805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33806</th>\n",
       "      <td>33806</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33807</th>\n",
       "      <td>33807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33808 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  y\n",
       "0          0  1\n",
       "1          1  0\n",
       "2          2  3\n",
       "3          3  1\n",
       "4          4  1\n",
       "...      ... ..\n",
       "33803  33803  0\n",
       "33804  33804  0\n",
       "33805  33805  1\n",
       "33806  33806  2\n",
       "33807  33807  0\n",
       "\n",
       "[33808 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        'id': submission_.id,\n",
    "        'y' : np.argmax(submission_[[0, 1, 2, 3, 4, 5, 6, 7]].values, axis=1)\n",
    "    }\n",
    ")\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a32bd93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:13:29.124111Z",
     "iopub.status.busy": "2021-06-09T13:13:29.123184Z",
     "iopub.status.idle": "2021-06-09T13:13:29.300138Z",
     "shell.execute_reply": "2021-06-09T13:13:29.299158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.369573\n",
       "1    0.273226\n",
       "2    0.174603\n",
       "3    0.124650\n",
       "4    0.039391\n",
       "5    0.010913\n",
       "6    0.000642\n",
       "7    0.007003\n",
       "Name: y, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.344800\n",
       "1    0.418215\n",
       "2    0.077230\n",
       "3    0.145261\n",
       "4    0.011329\n",
       "5    0.001804\n",
       "6    0.000266\n",
       "7    0.001094\n",
       "Name: y, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6., 5.))\n",
    "fig.add_subplot(2, 1, 1)\n",
    "sns.countplot(data=train, x='y')\n",
    "fig.add_subplot(2, 1, 2)\n",
    "sns.countplot(data=submission, x='y')\n",
    "display(train.y.value_counts(normalize=True).sort_index())\n",
    "display(submission.y.value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "946e213a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:13:29.303115Z",
     "iopub.status.busy": "2021-06-09T13:13:29.303115Z",
     "iopub.status.idle": "2021-06-09T13:13:29.348111Z",
     "shell.execute_reply": "2021-06-09T13:13:29.348111Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(OUTPUT_DIR, SUB_FILENAME), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af32dd1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:13:29.353114Z",
     "iopub.status.busy": "2021-06-09T13:13:29.353114Z",
     "iopub.status.idle": "2021-06-09T13:13:29.367158Z",
     "shell.execute_reply": "2021-06-09T13:13:29.366153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6909117830268913, 0.15368552603715158)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.loc['mean', 'train'], metrics.loc['mean', 'valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "402551d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:13:29.374150Z",
     "iopub.status.busy": "2021-06-09T13:13:29.373117Z",
     "iopub.status.idle": "2021-06-09T13:13:29.381147Z",
     "shell.execute_reply": "2021-06-09T13:13:29.380113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"087_submission.csv\",\"GroupK-Fold(pitcherID)\",\"0.690912\",\"0.153686\",\"\",\"Decision-function/Predict-probaの取得\"\n"
     ]
    }
   ],
   "source": [
    "print('\"{}\",\"{}\",\"{:.6f}\",\"{:.6f}\",\"\",\"{}\"'.format(SUB_FILENAME, CV, metrics.loc['mean', 'train'], metrics.loc['mean', 'valid'], NOTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48e83b76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:13:29.387142Z",
     "iopub.status.busy": "2021-06-09T13:13:29.387142Z",
     "iopub.status.idle": "2021-06-09T13:14:02.109754Z",
     "shell.execute_reply": "2021-06-09T13:14:02.109754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "imp_df = pd.DataFrame()\n",
    "for i, final_estimator in enumerate(models):\n",
    "    try:\n",
    "        if hasattr(final_estimator, 'feature_importances_'):\n",
    "            feature_importance = final_estimator.feature_importances_\n",
    "        else:\n",
    "            feature_importance = final_estimator.final_estimator.get_feature_importance()\n",
    "            \n",
    "        if hasattr(final_estimator, 'feature_name_'):\n",
    "            feature_names = final_estimator.feature_name_\n",
    "        elif hasattr(final_estimator, 'feature_names_'):\n",
    "            feature_names = final_estimator.feature_names_\n",
    "        else:\n",
    "            feature_names = final_estimator.get_booster().feature_names\n",
    "        imp_df_ = pd.DataFrame(\n",
    "            {\n",
    "                'feature': feature_names,\n",
    "                'importance': feature_importance\n",
    "            }\n",
    "        )\n",
    "        imp_df_['fold'] = i + 1\n",
    "        imp_df = pd.concat([imp_df, imp_df_])\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "if imp_df.shape[0] > 0:\n",
    "    imp_df.to_csv(os.path.join(OUTPUT_DIR, 'feature_importances.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01fa8bcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:14:02.109754Z",
     "iopub.status.busy": "2021-06-09T13:14:02.109754Z",
     "iopub.status.idle": "2021-06-09T13:14:02.125378Z",
     "shell.execute_reply": "2021-06-09T13:14:02.125378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9588f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:14:02.125378Z",
     "iopub.status.busy": "2021-06-09T13:14:02.125378Z",
     "iopub.status.idle": "2021-06-09T13:14:02.141003Z",
     "shell.execute_reply": "2021-06-09T13:14:02.141003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "coef_df = pd.DataFrame()\n",
    "for i, final_estimator in enumerate(models):\n",
    "    try:\n",
    "        if hasattr(final_estimator, 'coef_'):\n",
    "            coefficient = final_estimator.coef_\n",
    "            coef_df_ = pd.DataFrame(coefficient, columns=final_estimator.feature_names__)\n",
    "            coef_df_['fold'] = i + 1\n",
    "            coef_df_['y'] = final_estimator.classes_\n",
    "            coef_df = pd.concat([coef_df, coef_df_])\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "if coef_df.shape[0] > 0:\n",
    "    coef_df.to_csv(os.path.join(OUTPUT_DIR, 'coefficients.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d84066bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T13:14:02.141003Z",
     "iopub.status.busy": "2021-06-09T13:14:02.141003Z",
     "iopub.status.idle": "2021-06-09T13:14:02.156626Z",
     "shell.execute_reply": "2021-06-09T13:14:02.156626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm0</th>\n",
       "      <th>lgbm1</th>\n",
       "      <th>lgbm2</th>\n",
       "      <th>lgbm3</th>\n",
       "      <th>lgbm4</th>\n",
       "      <th>lgbm5</th>\n",
       "      <th>lgbm6</th>\n",
       "      <th>lgbm7</th>\n",
       "      <th>xgb0</th>\n",
       "      <th>xgb1</th>\n",
       "      <th>...</th>\n",
       "      <th>knn0</th>\n",
       "      <th>knn1</th>\n",
       "      <th>knn2</th>\n",
       "      <th>knn3</th>\n",
       "      <th>knn4</th>\n",
       "      <th>knn5</th>\n",
       "      <th>knn6</th>\n",
       "      <th>knn7</th>\n",
       "      <th>fold</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.324196</td>\n",
       "      <td>1.492957</td>\n",
       "      <td>0.889401</td>\n",
       "      <td>0.540191</td>\n",
       "      <td>-1.021805</td>\n",
       "      <td>-1.526890</td>\n",
       "      <td>-0.491525</td>\n",
       "      <td>-0.971677</td>\n",
       "      <td>9.418586</td>\n",
       "      <td>0.078061</td>\n",
       "      <td>...</td>\n",
       "      <td>1.939126</td>\n",
       "      <td>-0.204630</td>\n",
       "      <td>0.161135</td>\n",
       "      <td>-0.859921</td>\n",
       "      <td>-0.878486</td>\n",
       "      <td>-0.166151</td>\n",
       "      <td>0.053212</td>\n",
       "      <td>0.190563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.826942</td>\n",
       "      <td>0.540219</td>\n",
       "      <td>0.729045</td>\n",
       "      <td>1.188064</td>\n",
       "      <td>-0.211289</td>\n",
       "      <td>-1.393984</td>\n",
       "      <td>-0.668125</td>\n",
       "      <td>-0.875735</td>\n",
       "      <td>-0.763212</td>\n",
       "      <td>9.657410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095877</td>\n",
       "      <td>1.867382</td>\n",
       "      <td>0.294961</td>\n",
       "      <td>-1.322071</td>\n",
       "      <td>-0.467645</td>\n",
       "      <td>-0.228697</td>\n",
       "      <td>-0.185733</td>\n",
       "      <td>0.081063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.074822</td>\n",
       "      <td>2.135125</td>\n",
       "      <td>0.133581</td>\n",
       "      <td>0.805919</td>\n",
       "      <td>-1.254277</td>\n",
       "      <td>-1.843360</td>\n",
       "      <td>0.327240</td>\n",
       "      <td>-1.251548</td>\n",
       "      <td>-0.702511</td>\n",
       "      <td>-2.618440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.327129</td>\n",
       "      <td>-0.367152</td>\n",
       "      <td>1.802277</td>\n",
       "      <td>-0.061439</td>\n",
       "      <td>-0.292543</td>\n",
       "      <td>-0.129522</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>-0.504019</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.688961</td>\n",
       "      <td>1.198442</td>\n",
       "      <td>0.401550</td>\n",
       "      <td>0.363716</td>\n",
       "      <td>-0.409357</td>\n",
       "      <td>-1.138255</td>\n",
       "      <td>-0.531743</td>\n",
       "      <td>-1.594549</td>\n",
       "      <td>-2.419730</td>\n",
       "      <td>-1.563086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.787157</td>\n",
       "      <td>-0.806316</td>\n",
       "      <td>-0.938452</td>\n",
       "      <td>2.900802</td>\n",
       "      <td>-0.060874</td>\n",
       "      <td>-0.290234</td>\n",
       "      <td>-0.019638</td>\n",
       "      <td>-0.019367</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.255508</td>\n",
       "      <td>-1.516420</td>\n",
       "      <td>0.353199</td>\n",
       "      <td>-1.079578</td>\n",
       "      <td>4.481001</td>\n",
       "      <td>-0.420612</td>\n",
       "      <td>-0.347173</td>\n",
       "      <td>-0.426679</td>\n",
       "      <td>-2.118240</td>\n",
       "      <td>-1.796255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189378</td>\n",
       "      <td>0.088473</td>\n",
       "      <td>-0.848143</td>\n",
       "      <td>-1.088324</td>\n",
       "      <td>1.469539</td>\n",
       "      <td>0.382347</td>\n",
       "      <td>0.013766</td>\n",
       "      <td>-0.040051</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.530239</td>\n",
       "      <td>1.075892</td>\n",
       "      <td>-0.047282</td>\n",
       "      <td>0.655793</td>\n",
       "      <td>-0.381532</td>\n",
       "      <td>-0.828733</td>\n",
       "      <td>-0.414167</td>\n",
       "      <td>-1.650456</td>\n",
       "      <td>-2.276504</td>\n",
       "      <td>-2.064118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.946119</td>\n",
       "      <td>-1.193913</td>\n",
       "      <td>-0.762052</td>\n",
       "      <td>2.754981</td>\n",
       "      <td>0.159179</td>\n",
       "      <td>0.076437</td>\n",
       "      <td>-0.028160</td>\n",
       "      <td>-0.120599</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.866553</td>\n",
       "      <td>-1.618482</td>\n",
       "      <td>0.405291</td>\n",
       "      <td>-0.876111</td>\n",
       "      <td>4.756009</td>\n",
       "      <td>-0.726659</td>\n",
       "      <td>-0.162894</td>\n",
       "      <td>-0.155807</td>\n",
       "      <td>-1.666192</td>\n",
       "      <td>-1.675031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.392711</td>\n",
       "      <td>0.143083</td>\n",
       "      <td>-0.909101</td>\n",
       "      <td>-0.718258</td>\n",
       "      <td>1.602148</td>\n",
       "      <td>-0.078253</td>\n",
       "      <td>0.031960</td>\n",
       "      <td>0.075925</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.468838</td>\n",
       "      <td>-1.420146</td>\n",
       "      <td>-1.197469</td>\n",
       "      <td>-0.718320</td>\n",
       "      <td>-0.880175</td>\n",
       "      <td>5.857034</td>\n",
       "      <td>-0.082398</td>\n",
       "      <td>-0.154365</td>\n",
       "      <td>-1.599267</td>\n",
       "      <td>-1.366344</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.033147</td>\n",
       "      <td>0.355208</td>\n",
       "      <td>-0.110685</td>\n",
       "      <td>0.320872</td>\n",
       "      <td>0.070619</td>\n",
       "      <td>0.328962</td>\n",
       "      <td>-0.001770</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.446483</td>\n",
       "      <td>-0.806099</td>\n",
       "      <td>-0.403568</td>\n",
       "      <td>-0.214778</td>\n",
       "      <td>-0.147456</td>\n",
       "      <td>-0.115505</td>\n",
       "      <td>2.196672</td>\n",
       "      <td>-0.075988</td>\n",
       "      <td>-0.558473</td>\n",
       "      <td>-0.675529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255295</td>\n",
       "      <td>-0.240499</td>\n",
       "      <td>0.034932</td>\n",
       "      <td>-0.169484</td>\n",
       "      <td>-0.033510</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>0.144166</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.261327</td>\n",
       "      <td>-1.602506</td>\n",
       "      <td>-0.993138</td>\n",
       "      <td>-0.625576</td>\n",
       "      <td>-0.468510</td>\n",
       "      <td>-0.326085</td>\n",
       "      <td>-0.104912</td>\n",
       "      <td>5.290323</td>\n",
       "      <td>-1.158083</td>\n",
       "      <td>-1.601828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198121</td>\n",
       "      <td>-0.377862</td>\n",
       "      <td>-0.467578</td>\n",
       "      <td>0.377656</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>-0.123141</td>\n",
       "      <td>-0.001795</td>\n",
       "      <td>0.297771</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lgbm0     lgbm1     lgbm2     lgbm3     lgbm4     lgbm5     lgbm6  \\\n",
       "0   1.324196  1.492957  0.889401  0.540191 -1.021805 -1.526890 -0.491525   \n",
       "1   0.826942  0.540219  0.729045  1.188064 -0.211289 -1.393984 -0.668125   \n",
       "2   1.074822  2.135125  0.133581  0.805919 -1.254277 -1.843360  0.327240   \n",
       "3   1.688961  1.198442  0.401550  0.363716 -0.409357 -1.138255 -0.531743   \n",
       "4  -1.255508 -1.516420  0.353199 -1.079578  4.481001 -0.420612 -0.347173   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "3   1.530239  1.075892 -0.047282  0.655793 -0.381532 -0.828733 -0.414167   \n",
       "4  -1.866553 -1.618482  0.405291 -0.876111  4.756009 -0.726659 -0.162894   \n",
       "5  -1.468838 -1.420146 -1.197469 -0.718320 -0.880175  5.857034 -0.082398   \n",
       "6  -0.446483 -0.806099 -0.403568 -0.214778 -0.147456 -0.115505  2.196672   \n",
       "7  -1.261327 -1.602506 -0.993138 -0.625576 -0.468510 -0.326085 -0.104912   \n",
       "\n",
       "       lgbm7      xgb0      xgb1  ...      knn0      knn1      knn2      knn3  \\\n",
       "0  -0.971677  9.418586  0.078061  ...  1.939126 -0.204630  0.161135 -0.859921   \n",
       "1  -0.875735 -0.763212  9.657410  ...  0.095877  1.867382  0.294961 -1.322071   \n",
       "2  -1.251548 -0.702511 -2.618440  ... -0.327129 -0.367152  1.802277 -0.061439   \n",
       "3  -1.594549 -2.419730 -1.563086  ... -0.787157 -0.806316 -0.938452  2.900802   \n",
       "4  -0.426679 -2.118240 -1.796255  ... -0.189378  0.088473 -0.848143 -1.088324   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "3  -1.650456 -2.276504 -2.064118  ... -0.946119 -1.193913 -0.762052  2.754981   \n",
       "4  -0.155807 -1.666192 -1.675031  ... -0.392711  0.143083 -0.909101 -0.718258   \n",
       "5  -0.154365 -1.599267 -1.366344  ... -1.033147  0.355208 -0.110685  0.320872   \n",
       "6  -0.075988 -0.558473 -0.675529  ...  0.255295 -0.240499  0.034932 -0.169484   \n",
       "7   5.290323 -1.158083 -1.601828  ...  0.198121 -0.377862 -0.467578  0.377656   \n",
       "\n",
       "        knn4      knn5      knn6      knn7  fold  y  \n",
       "0  -0.878486 -0.166151  0.053212  0.190563     1  0  \n",
       "1  -0.467645 -0.228697 -0.185733  0.081063     1  1  \n",
       "2  -0.292543 -0.129522  0.007026 -0.504019     1  2  \n",
       "3  -0.060874 -0.290234 -0.019638 -0.019367     1  3  \n",
       "4   1.469539  0.382347  0.013766 -0.040051     1  4  \n",
       "..       ...       ...       ...       ...   ... ..  \n",
       "3   0.159179  0.076437 -0.028160 -0.120599    10  3  \n",
       "4   1.602148 -0.078253  0.031960  0.075925    10  4  \n",
       "5   0.070619  0.328962 -0.001770  0.005265    10  5  \n",
       "6  -0.033510 -0.002155  0.144166 -0.001953    10  6  \n",
       "7   0.005096 -0.123141 -0.001795  0.297771    10  7  \n",
       "\n",
       "[80 rows x 42 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0412c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_.to_csv(os.path.join(OUTPUT_DIR, 'submission_集計前.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d5227c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.819457</td>\n",
       "      <td>5.578425</td>\n",
       "      <td>3.357713</td>\n",
       "      <td>0.244383</td>\n",
       "      <td>2.157882e-05</td>\n",
       "      <td>1.479065e-08</td>\n",
       "      <td>1.863097e-10</td>\n",
       "      <td>1.605099e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.720541</td>\n",
       "      <td>3.546693</td>\n",
       "      <td>0.423448</td>\n",
       "      <td>0.309317</td>\n",
       "      <td>3.598138e-07</td>\n",
       "      <td>4.611904e-08</td>\n",
       "      <td>2.999032e-10</td>\n",
       "      <td>5.287230e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.131112</td>\n",
       "      <td>0.313633</td>\n",
       "      <td>0.301445</td>\n",
       "      <td>9.250581</td>\n",
       "      <td>3.044975e-03</td>\n",
       "      <td>1.014315e-08</td>\n",
       "      <td>2.657503e-08</td>\n",
       "      <td>1.845510e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.525217</td>\n",
       "      <td>5.632873</td>\n",
       "      <td>0.762354</td>\n",
       "      <td>0.079555</td>\n",
       "      <td>6.715158e-07</td>\n",
       "      <td>5.371278e-09</td>\n",
       "      <td>7.810772e-10</td>\n",
       "      <td>1.029124e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.745291</td>\n",
       "      <td>6.355201</td>\n",
       "      <td>0.464672</td>\n",
       "      <td>0.398726</td>\n",
       "      <td>3.611024e-02</td>\n",
       "      <td>3.457776e-08</td>\n",
       "      <td>1.318452e-09</td>\n",
       "      <td>3.632738e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33803</th>\n",
       "      <td>33803</td>\n",
       "      <td>8.449245</td>\n",
       "      <td>0.605091</td>\n",
       "      <td>0.527278</td>\n",
       "      <td>0.417942</td>\n",
       "      <td>4.427508e-04</td>\n",
       "      <td>2.186659e-08</td>\n",
       "      <td>2.467781e-09</td>\n",
       "      <td>2.942154e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33804</th>\n",
       "      <td>33804</td>\n",
       "      <td>5.529505</td>\n",
       "      <td>2.405217</td>\n",
       "      <td>0.475473</td>\n",
       "      <td>1.587440</td>\n",
       "      <td>2.364738e-03</td>\n",
       "      <td>4.958524e-09</td>\n",
       "      <td>3.787382e-10</td>\n",
       "      <td>4.003942e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33805</th>\n",
       "      <td>33805</td>\n",
       "      <td>2.195281</td>\n",
       "      <td>4.466306</td>\n",
       "      <td>1.837204</td>\n",
       "      <td>1.501207</td>\n",
       "      <td>2.246288e-07</td>\n",
       "      <td>1.243756e-09</td>\n",
       "      <td>2.434816e-09</td>\n",
       "      <td>1.679963e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33806</th>\n",
       "      <td>33806</td>\n",
       "      <td>1.642783</td>\n",
       "      <td>2.277561</td>\n",
       "      <td>5.408487</td>\n",
       "      <td>0.670123</td>\n",
       "      <td>1.045930e-03</td>\n",
       "      <td>3.387614e-08</td>\n",
       "      <td>1.058681e-09</td>\n",
       "      <td>1.641247e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33807</th>\n",
       "      <td>33807</td>\n",
       "      <td>6.826573</td>\n",
       "      <td>0.921803</td>\n",
       "      <td>0.446235</td>\n",
       "      <td>1.625875</td>\n",
       "      <td>1.795130e-01</td>\n",
       "      <td>7.199070e-08</td>\n",
       "      <td>8.995225e-09</td>\n",
       "      <td>2.292519e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33808 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         0         1         2         3             4  \\\n",
       "0          0  0.819457  5.578425  3.357713  0.244383  2.157882e-05   \n",
       "1          1  5.720541  3.546693  0.423448  0.309317  3.598138e-07   \n",
       "2          2  0.131112  0.313633  0.301445  9.250581  3.044975e-03   \n",
       "3          3  3.525217  5.632873  0.762354  0.079555  6.715158e-07   \n",
       "4          4  2.745291  6.355201  0.464672  0.398726  3.611024e-02   \n",
       "...      ...       ...       ...       ...       ...           ...   \n",
       "33803  33803  8.449245  0.605091  0.527278  0.417942  4.427508e-04   \n",
       "33804  33804  5.529505  2.405217  0.475473  1.587440  2.364738e-03   \n",
       "33805  33805  2.195281  4.466306  1.837204  1.501207  2.246288e-07   \n",
       "33806  33806  1.642783  2.277561  5.408487  0.670123  1.045930e-03   \n",
       "33807  33807  6.826573  0.921803  0.446235  1.625875  1.795130e-01   \n",
       "\n",
       "                  5             6             7  \n",
       "0      1.479065e-08  1.863097e-10  1.605099e-07  \n",
       "1      4.611904e-08  2.999032e-10  5.287230e-08  \n",
       "2      1.014315e-08  2.657503e-08  1.845510e-04  \n",
       "3      5.371278e-09  7.810772e-10  1.029124e-07  \n",
       "4      3.457776e-08  1.318452e-09  3.632738e-07  \n",
       "...             ...           ...           ...  \n",
       "33803  2.186659e-08  2.467781e-09  2.942154e-07  \n",
       "33804  4.958524e-09  3.787382e-10  4.003942e-07  \n",
       "33805  1.243756e-09  2.434816e-09  1.679963e-06  \n",
       "33806  3.387614e-08  1.058681e-09  1.641247e-07  \n",
       "33807  7.199070e-08  8.995225e-09  2.292519e-07  \n",
       "\n",
       "[33808 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2d7533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
